{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/r4isstatic/csv-to-ttl/blob/master/csv-ttl-convert-v1.py\n",
    "#import the CSV module for dealing with CSV files\n",
    "import csv\n",
    "\n",
    "#create a 'reader' variable, which allows us to play with the contents of the CSV file\n",
    "#in order to do that, we create the ifile variable, open the CSV file into that, then pass its' contents into the reader variable.\n",
    "ifile = open('paper_hyp_entity_data.csv', 'rb')\n",
    "reader = csv.reader(ifile)\n",
    "\n",
    "#create a new variable called 'outfile' (could be any name), which we'll use to create a new file that we'll pass our TTL into.\n",
    "outfile = open('HypothesisEntityInstances.ttl', 'a')\n",
    "\n",
    "#get python to loop through each row in the CSV, and ignore the first row.\n",
    "rownum = 0\n",
    "for row in reader:\n",
    "    if rownum == 0: # if it's the first row, then ignore it, move on to the next one.\n",
    "        pass\n",
    "    else: # if it's not the first row, place the contents of the row into the 'c' variable, then create a 'd' variable with the stuff we want in the file.\n",
    "        c = row\n",
    "        d = '<' c[1] + '> oa:hasSource fabio:Abstract.\\n'\n",
    "        entity_list = []\n",
    "        for i in c[7]:\n",
    "            i = i.replace('[', '')   \n",
    "            i = i.replace(']', '') \n",
    "            i = i.replace(\"'\", '')\n",
    "            entity_list.append(i)\n",
    "        # abstract instances\n",
    "#         e = 'fabio:Abstract rdf:value ' + c[5] + '; \\n hyp:contains' + entity_list + '. \\n'\n",
    "        # hypothesis instances\n",
    "#         f = c[1] + ' rdf:value ' + c[6] + '; \\n hyp:contains' + entity_list + '. \\n'\n",
    "        f = core:preferredLabel \"' + c[2] + '\" ;\\n core:sameAs <' + c[3] + '> .\\n \\n'\n",
    "        outfile.write(d)\t# now write the d variable into the file\n",
    "    rownum += 1 # advance the row number so we can loop through again with the next row\n",
    "\n",
    "# finish off by closing the two files we created\n",
    "\n",
    "outfile.close()\n",
    "ifile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['the_inhibitors', 'viral_p7', 'a_new_class', ...\n",
       "1      ['VNAs', 'the_CNS', 'B_cells', 'the_periphery'...\n",
       "2      ['our_findings', 'a_review', 'the_current_lite...\n",
       "3      ['the_surface_charge_distribution', 'dictates'...\n",
       "4      ['Our_findings support the_virus-host_co-evolu...\n",
       "                             ...                        \n",
       "546    ['oral_VA_supplementation', 'porcine_epidemic_...\n",
       "547    ['Dietary_fats', 'sodium', 'ingestive_behavior...\n",
       "548    ['However , apparent_constraints', 'the_size',...\n",
       "549    ['The_precise_neuropathogenesis', 'rabies', 'n...\n",
       "550    ['Structural_similarities', 'ascovirus_and_ich...\n",
       "Name: hypothesis_entities, Length: 551, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('paper_hyp_entity_data.csv')\n",
    "test = data.hypothesis_entities\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_inhibitors, viral_p7, a_new_class, potent_agents, further_confirmation, vitro, vivo <class 'str'>\n",
      "VNAs, the_CNS, B_cells, the_periphery, the_CNS, RABV, the_CNS <class 'str'>\n",
      "our_findings, a_review, the_current_literature, s2m, a_hypothesis, an_RNAi-like_function, the_s2m_element <class 'str'>\n",
      "the_surface_charge_distribution, dictates, the_components, aggregation, viral_stability, infectivity <class 'str'>\n",
      "Our_findings support the_virus-host_co-evolution_hypothesis, Miniopterus_bat_coronavirus_HKU8, Miniopterus_species, China, Hong_Kong, Bulgaria, Australian_Miniopterus_species <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "clean_items = []\n",
    "for i in test[:5]:\n",
    "    i = i.replace('[', '')   \n",
    "    i = i.replace(']', '') \n",
    "    i = i.replace(\"'\", '')\n",
    "    clean_items.append(i)\n",
    "for x in clean_items:\n",
    "    print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
